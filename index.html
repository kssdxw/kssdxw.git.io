<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Ryan&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="TEST">
<meta property="og:type" content="website">
<meta property="og:title" content="Ryan&#39;s Blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Ryan&#39;s Blog">
<meta property="og:description" content="TEST">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Ryan">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Ryan&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Ryan&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-kubernetes网络模型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/06/kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time datetime="2020-11-06T09:33:32.000Z" itemprop="datePublished">2020-11-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/06/kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">kubernetes网络模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>计算、存储和网络是云时代的三大基础服务，作为新一代基础架构的 Kubernetes 也不例外。而这三者之中，网络又是一个最难掌握和最容易出问题的服务；本文通过对Kubernetes网络流量模型进行简单梳理，希望对初学者能够提供一定思路。先看一下kubernetes 总体模型：</p>
<p><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k1.png"></p>
<h4 id="容器网络中涉及的几个地址："><a href="#容器网络中涉及的几个地址：" class="headerlink" title="容器网络中涉及的几个地址："></a>容器网络中涉及的几个地址：</h4><p>Node Ip：物理机地址。<br>POD Ip：Kubernetes的最小部署单元是Pod，一个pod 可能包含一个或多个容器，简单来讲容器没有自己单独的地址，他们共享POD 的地址和端口区间。<br>ClusterIp：Service的Ip地址，外部网络无法ping通改地址，因为它是虚拟IP地址，没有网络设备为这个地址负责，内部实现是使用Iptables规则重新定向到其本地端口，再均衡到后端Pod；只有Kubernetes集群内部访问使用。<br>Public Ip ：Service对象在Cluster IP range池中分配到的IP只能在内部访问，适合作为一个应用程序内部的层次。如果这个Service作为前端服务，准备为集群外的客户提供业务，我们就需要给这个服务提供公共IP。</p>
<h2 id="容器网络流量模型"><a href="#容器网络流量模型" class="headerlink" title="容器网络流量模型"></a>容器网络流量模型</h2><p>容器网络至少需要解决如下几种场景的通信：</p>
<p>①POD内容器间通信<br>②同主机POD间 通信<br>③跨主机POD间 通信<br>④集群内Service Cluster Ip和外部访问</p>
<p>下面具体介绍实现方式</p>
<h4 id="POD内容器间通信"><a href="#POD内容器间通信" class="headerlink" title="POD内容器间通信"></a>POD内容器间通信</h4><p>Pod中的容器可以通过“localhost”来互相通信，他们使用同一个网络命名空间，对容器来说，hostname就是Pod的名称。Pod中的所有容器共享同一个IP地址和端口空间，你需要为每个需要接收连接的容器分配不同的端口。也就是说，Pod中的应用需要自己协调端口的使用。</p>
<p>实验如下：</p>
<p>首先我们创建一个Pod ，包含两个容器，容器参数如下：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k2.jpg"><br>查看：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k3.PNG"><br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k4.png"><br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k5.png"></p>
<p>可以看到容器共享Pod 的地址，那么他们是否使用同一端口资源呢，我们可以简单实验一下：首先在容器1监听一个端口：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k6.PNG"><br>然后在容器2查看该端口是否被占用：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k7.PNG"><br>可见端口也是共享的；所以简单理解，可以把Pod看做一个小系统，容器当做系统中的不同进程；</p>
<p>内部实现：同POD 内的容器实际共享同一个Namespace，因此使用相同的Ip和Port空间，该Namespace 是由一个叫Pause的小容器来实现，每当一个Pod被创建，那么首先创建一个pause容器， 之后这个pod里面的其他容器通过共享这个pause容器的网络栈，实现外部pod进行通信,因此对于同Pod里面的所有容器来说，他们看到的网络视图是一样的，我们在容器中看的地址，也就是Pod地址实际是Pause容器的IP地址。总体模型如下：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k8.png"><br>我们在node 节点查看之前创建的POD，可以看到该pause容器 ：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k9.PNG"><br>这种新创建的容器和已经存在的一个容器(pause)共享一个 Network Namespace（而不是和宿主机共享） 就是我们常说的container 模式。</p>
<h4 id="同主机POD间通信"><a href="#同主机POD间通信" class="headerlink" title="同主机POD间通信"></a>同主机POD间通信</h4><p>每个节点上的每个Pod都有自己的namespace，同主机上的POD之间怎么通信呢？我们可以在两个POD之间建立Vet Pair进行通信，但如果有多个容器，两两建立Veth 就会非常麻烦，假如有N 个POD ，那么我们需要创建n(n-1)/2个Veth Pair，扩展性非常差，如果我们可以将这些Veth Pair 连接到一个集中的转发点，由它来统一转发就就会非常便捷，这个集中转发点就是我们常说的bridge；如下所示（简单起见，这里把pause忽略）：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k10.png"><br>仍然以我们的测试环境为例，创建pod1 和pod2地址分别为：10.244.1.16、10.244.1.18，位于node1 节点<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k11.PNG"><br>查看节点下的namespace：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k12.PNG"><br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k13.PNG"><br>这两个NS就是上述两个POD 对应的namespace，查询对应namespace 下的接口：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k14.PNG"><br>可以看到标红处的地址，实际就是POD 的ip地址；</p>
<p>NS 和对应的POD 地址都找到了，那么如何确认这两个ns 下的虚接口的另一端呢? 比较直观的确认方式为：上述接口如 3: eth0@if7，表示本端接口id 为3 ，对端接口id是7，我们看下default namespace（我们平时看的默认都在default下） 的veth口：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k15.PNG"><br>7: veth3b416eb5@if3 ，该接口的id 正是我们要找的id 为7的接口 ，是veth pair的另一端；</p>
<h2 id="跨node通信"><a href="#跨node通信" class="headerlink" title="跨node通信"></a>跨node通信</h2><p>跨node通信就涉及到了Container Network Interface的实现，也就是容器网络的API，它有一定的要求，简要下来有三点</p>
<ol>
<li>运行在一个节点当中的Pod能在不经过NAT的情况下跟集群中所有的Pod进行通信</li>
<li>节点当中的客户端（system daemon、kubelet）能跟该节点当中的所有Pod进行通信</li>
<li>以host network模式运行在一个节点上的Pod能跟集群中所有的Pod进行通信</li>
</ol>
<p>针对Kubernetes网络模型也涌现出了许多的实现方案，例如Calico、Flannel、Weave等等，虽然实现原理各有千秋，但都围绕着同一个问题即如何实现Kubernetes当中的扁平网络进行展开。Kubernetes只需要负责编排调度相关的事情，修桥铺路的事情交给相应的网络插件即可，我们会以Flannel为例进行讲解。</p>
<h4 id="Flannel"><a href="#Flannel" class="headerlink" title="Flannel"></a>Flannel</h4><p>不过多讲述部署过程，在安装部署完成之后应该能看到在各个节点上通过DaemonSet的方式运行了一个Flannel的Pod。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# kubectl get daemonset -n kube-system -l app&#x3D;flannel</span><br><span class="line">NAME              DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR                   AGE</span><br><span class="line">kube-flannel-ds   3         3         3         3            3           beta.kubernetes.io&#x2F;arch&#x3D;amd64   135d</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line">[root@10-10-88-192 ~]# kubectl get pod -n kube-system -o wide -l app&#x3D;flannel</span><br><span class="line">NAME                    READY     STATUS    RESTARTS   AGE       IP               NODE</span><br><span class="line">kube-flannel-ds-npcxv   1&#x2F;1       Running   0          2h        172.16.130.164   10-10-88-170</span><br><span class="line">kube-flannel-ds-rv8wv   1&#x2F;1       Running   0          2h        172.16.130.244   10-10-88-192</span><br><span class="line">kube-flannel-ds-t5zlv   1&#x2F;1       Running   0          2h        172.16.130.140   10-10-88-195</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>每一个Flannel的Pod当中都运行了一个flanneld进程，且flanneld的配置文件以ConfigMap的形式挂载到容器内的/etc/kube-flannel/目录供flanneld使用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# kubectl get cm -n kube-system -l app&#x3D;flannel</span><br><span class="line">NAME               DATA      AGE</span><br><span class="line">kube-flannel-cfg   2         137d</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>Flannel Backend<br>Flannel通过在每一个节点上启动一个叫flanneld的进程，负责每一个节点上的子网划分，并将相关的配置信息如各个节点的子网网段、外部IP等保存到etcd当中，而具体的网络包转发交给具体的Backend来实现。<br>flanneld可以在启动的时候通过配置文件来指定不同的Backend来进行网络通信，目前比较成熟的Backend有VXLAN、host-gw以及UDP三种方式，也已经有诸如AWS，GCE and AliVPC这些还在实验阶段的Backend。VXLAN是目前官方最推崇的一种Backend实现方式，host-gw一般用于对网络性能要求比较高的场景，但需要基础架构本身的支持，UDP则一般用于Debug和一些比较老的不支持VXLAN的Linux内核。<br>这里只简单介绍一下两种Backend网络通信实现流程：</p>
<ul>
<li>UDP</li>
<li>VXLAN<h4 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h4>由于UDP模式相对容易理解，故这里先采用UDP这种Backend模式进行举例说明然后再对其他Backend模式进行展开讲解。<br>采用UDP模式时需要在flanneld的配置文件当中指定Backend type为UDP，可以通过直接修改flanneld的ConfigMap的方式实现，配置修改完成之后如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# kubectl get cm -n kube-system -o yaml kube-flannel-cfg</span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  cni-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;cbr0&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;flannel&quot;,</span><br><span class="line">      &quot;delegate&quot;: &#123;</span><br><span class="line">        &quot;isDefaultGateway&quot;: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  net-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;Network&quot;: &quot;10.244.0.0/16&quot;,</span><br><span class="line">      &quot;Backend&quot;: &#123;</span><br><span class="line">        &quot;Type&quot;: &quot;udp&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: 2018-10-30T08:34:01Z</span><br><span class="line">  labels:</span><br><span class="line">    app: flannel</span><br><span class="line">    tier: node</span><br><span class="line">  name: kube-flannel-cfg</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  resourceVersion: &quot;33718154&quot;</span><br><span class="line">  selfLink: /api/v1/namespaces/kube-system/configmaps/kube-flannel-cfg</span><br><span class="line">  uid: 8d981eff-dc1e-11e8-8103-fa900126bc00</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
关键字段为Backend当中的Type字段，采用UDP模式时Backend Port默认为8285，即flanneld的监听端口。</li>
</ul>
<p>flanneld的ConfigMap更新完成之后delete flannel pod进行配置更新：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# kubectl delete pod -n kube-system -l app&#x3D;flannel</span><br><span class="line">pod &quot;kube-flannel-ds-npcxv&quot; deleted</span><br><span class="line">pod &quot;kube-flannel-ds-rv8wv&quot; deleted</span><br><span class="line">pod &quot;kube-flannel-ds-t5zlv&quot; deleted</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>当采用UDP模式时，flanneld进程在启动时会通过打开/dev/net/tun的方式生成一个TUN设备，TUN设备可以简单理解为Linux当中提供的一种内核网络与用户空间（应用程序）通信的一种机制，即应用可以通过直接读写tun设备的方式收发RAW IP包。</p>
<p>flanneld进程启动后通过ip a命令可以发现节点当中已经多了一个叫flannel0的网络接口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link&#x2F;ether fa:90:01:26:bc:00 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.10.88.192&#x2F;24 brd 10.10.88.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f890:1ff:fe26:bc00&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link&#x2F;ether fa:86:b8:79:70:01 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.16.130.244&#x2F;24 brd 172.16.130.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f886:b8ff:fe79:7001&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN</span><br><span class="line">    link&#x2F;ether 02:42:ae:dd:19:83 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1&#x2F;16 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: flannel0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1472 qdisc pfifo_fast state UNKNOWN qlen 500</span><br><span class="line">    link&#x2F;none</span><br><span class="line">    inet 10.244.0.0&#x2F;16 scope global flannel0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::969a:a8eb:e4da:308b&#x2F;64 scope link flags 800</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1472 qdisc noqueue state UP qlen 1000</span><br><span class="line">    link&#x2F;ether 0a:58:0a:f4:00:01 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.244.0.1&#x2F;24 scope global cni0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::3428:a4ff:fe6c:bb77&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>细心的同学就会发现此时flannel0这个网络接口上的MTU为1472，相比Kubernetes集群网络接口eth1小了28个字节，为什么呢？</p>
<p>通过可以ip -d link show flannel0可以看到这是一个tun设备：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# ip -d link show flannel0</span><br><span class="line">5: flannel0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1472 qdisc pfifo_fast state UNKNOWN mode DEFAULT qlen 500</span><br><span class="line">    link&#x2F;none  promiscuity 0</span><br><span class="line">    tun</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>通过netstat -ulnp命令可以看到此时flanneld进程监听在8285端口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# netstat -ulnp | grep flanneld</span><br><span class="line">udp        0      0 172.16.130.140:8285     0.0.0.0:*                           2373&#x2F;flanneld</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>容器跨节点通信实现流程：</p>
<p>假设在节点A上有容器A（10.244.1.96），在节点B上有容器B（10.244.2.194），此时容器A向容器发送一个ICMP请求报文（ping），我们来逐步分析一下ICMP报文是如何从容器A到达容器B的。<br><img src="https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/b8f4da7a3c4a65c48d227481279073b8.png"></p>
<p>1、容器A当中发出ICMP请求报文，通过IP封装后形式为：10.244.1.96 -&gt; 10.244.2.194，此时通过容器A内的路由表匹配到应该将IP包发送到网关10.244.1.1（cni0网桥）。</p>
<p>完整的帧格式为：</p>
<p><img src="https://static001.infoq.cn/resource/image/43/df/43e371ee592ce23150091959343aa4df.png"><br>2、此时到达cni0的IP包目的地IP 10.244.2.194匹配到节点A上第一条路由规则（10.244.0.0），内核将RAW IP包发送给flannel0接口。<br>3、flannel0为tun设备，发送给flannel0接口的RAW IP包（无MAC信息）将被flanneld进程接收到，flanneld进程接收到RAW IP包后在原有的基础上进行UDP封包，UDP封包的形式为：172.16.130.140:src port -&gt; 172.16.130.164:8285。<br>这里有一个问题就是flanneld怎么知道10.244.2.194这个容器到底是在哪个节点上呢？<br>flanneld在启动时会将该节点的网络信息通过api-server保存到etcd当中，故在发送报文时可以通过查询etcd得到10.244.2.194这个容器的IP属于host B，且host B的IP为172.16.130.164。<br>RAW IP包示例：<br><img src="https://static001.infoq.cn/resource/image/c8/f8/c8b8936834d450d273c2b4d11f1f1ef8.png"><br>4、flanneld将封装好的UDP报文经eth1发出，从这里可以看出网络包在通过eth1发出前先是加上了UDP头（8个字节），再然后加上了IP头（20个字节）进行封装，这也是为什么flannel0的MTU要比eth1的MTU小28个字节的原因（防止封装后的以太网帧超过eth1的MTU而在经过eth1时被丢弃）。<br>此时完整的以太网帧格式为：<br><img src="https://static001.infoq.cn/resource/image/99/52/99412b1688581f0444f334e7796b0052.png"><br>5、网络包经节点A和节点B之间的网络连接到达host B。<br>6、host B收到UDP报文后经Linux内核通过UDP端口号8285将包交给正在监听的应用flanneld。<br>7、运行在host B当中的flanneld将UDP包解包后得到RAW IP包：10.244.1.96 -&gt; 10.244.2.194。<br>8、解封后的RAW IP包匹配到host B上的路由规则（10.244.2.0），内核将RAW IP包发送到cni0。<br>此时的完整的以太网帧格式为：<br><img src="https://static001.infoq.cn/resource/image/07/d1/073754a577bae1489a633c004538d6d1.png"><br>9、cni0将IP包转发给连接在cni0网桥上的container B，而flanneld在整个过程中主要主要负责两个工作：</p>
<ul>
<li>UDP封包解包</li>
<li>节点上的路由表的动态更新<br>从上面虚线部分就可以看到container A和container B虽然在物理网络上并没有直接相连，但在逻辑上就好像是处于同一个三层网络当中，这种基于底下的物理网络设备通过Flannel等软件定义网络技术实现的网络我们称之为Overlay网络。<br>那么上面通过UDP这种Backend实现的网络传输过程有没有问题呢？最明显的问题就是，网络数据包先是通过tun设备从内核当中复制到用户态的应用，然后再由用户态的应用复制到内核，仅一次网络传输就进行了两次用户态和内核态的切换，显然这种效率是不会很高的。那么有没有高效一点的办法呢？当然，最简单的方式就是把封包解包这些事情都交给内核去干好了，事实上Linux内核本身也提供了比较成熟的网络封包解包（隧道传输）实现方案VXLAN，下面我们就来看看通过内核的VXLAN跟flanneld自己通过UDP封装网络包在实现上有什么差别。<h4 id="VXLAN"><a href="#VXLAN" class="headerlink" title="VXLAN"></a>VXLAN</h4>VXLAN全称Virtual Extensible LAN，是一种虚拟化隧道通信技术，主要是为了突破VLAN的最多4096个子网的数量限制，以满足大规模云计算数据中心的需求。VLAN技术的缺陷是VLAN Header预留的长度只有12 bit，故最多只能支持2的12次方即4096个子网的划分，无法满足云计算场景下主机数量日益增长的需求。当前VXLAN的报文Header内有24 bit，可以支持2的24次方个子网，并通过VNI（Virtual Network Identifier）来区分不同的子网，相当于VLAN当中的VLAN ID。<br>不同于其他隧道协议，VXLAN是一个一对多的网络，并不仅仅是一对一的隧道协议。一个VXLAN设备能通过像网桥一样的学习方式学习到其他对端的IP地址，也可以直接配置静态转发表。<br>VXLAN包格式：<br><img src="https://static001.infoq.cn/resource/image/93/ba/936636bee23136bf16a6d1cdb47d98ba.png"><br>从VXLAN的包格式就可以看到原本的二层以太网帧被放在VXLAN包头里进行封装，VXLAN实际实现的是一个二层网络的隧道，通过VXLAN让处于同一个VXLAN网络（VNI相同则为同一个VXLAN网络）当中的机器看似处在同一个二层网络当中（逻辑上处于同一个二层网络），而网络包转发的方式也类似二层网络当中的交换机（这样虽然不是很准确，但更便于理解）。<br>当采用VXLAN模式时，flanneld在启动时会通过Netlink机制与Linux内核通信，建立一个VTEP（Virtual Tunnel Access End Point）设备flannel.1 （命名规则为flannel.[VNI]，VNI默认为1），类似于交换机当中的一个网口。<br>可以通过ip -d link查看VTEP设备flannel.1的配置信息，从以下输出可以看到，VTEP的local IP为172.16.130.244，destination port为8472。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# ip -d link show flannel.1</span><br><span class="line">5: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT</span><br><span class="line">    link&#x2F;ether a2:5e:b0:43:09:a7 brd ff:ff:ff:ff:ff:ff promiscuity 0</span><br><span class="line">    vxlan id 1 local 172.16.130.244 dev eth1 srcport 0 0 dstport 8472 nolearning ageing 300 addrgenmode eui64</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>
在UDP模式下由flanneld进程进行网络包的封包和解包的工作，而在VXLAN模式下解封包的事情交由内核处理，那么此时FlannnelD的作用是什么呢？带着这个疑问我们先来简单看一下VXLAN Backend是如何工作的。</li>
</ul>
<p>Flannel当中对VXLAN Backend的实现经过了几个版本的改进之后目前最新版本的flanneld当中的处理流程为：</p>
<p>当flanneld启动时将创建VTEP设备（默认为flannel.1，若已经创建则跳过），并将VTEP设备的相关信息上报到etcd当中，而当在Flannel网络中有新的节点发现时，各个节点上的flanneld将依次执行以下流程：</p>
<p>在节点当中创建一条该节点所属网段的路由表，主要是能让Pod当中的流量路由到flannel.1接口。</p>
<p>通过route -n可以查看到节点当中已经有两条flannel.1接口的路由：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         10.10.88.254    0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">10.10.88.0      0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br><span class="line">10.244.0.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0</span><br><span class="line">10.244.1.0      10.244.1.0      255.255.255.0   UG    0      0        0 flannel.1</span><br><span class="line">10.244.2.0      10.244.2.0      255.255.255.0   UG    0      0        0 flannel.1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">172.16.130.0    0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在节点当中添加一条该节点的IP以及VTEP设备的静态ARP缓存。<br>可通过arp -n命令查看到master节点当中已经缓存了另外两个节点以及VTEP的ARP信息（已删除无关ARP缓存信息）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# arp -n</span><br><span class="line">Address                  HWtype  HWaddress           Flags Mask            Iface</span><br><span class="line">10.244.2.0               ether   42:7f:69:c7:cd:37   CM                    flannel.1</span><br><span class="line">10.244.1.0               ether   7a:2c:d0:7f:48:3f   CM                    flannel.1</span><br><span class="line">172.16.130.140           ether   fa:89:cf:03:e3:01   C                     eth1</span><br><span class="line">172.16.130.164           ether   fa:88:2a:44:2b:01   C                     eth1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在节点当中添加一条该节点的转发表。<br>通过bridge命令查看节点上的VXLAN转发表（FDB entry），MAC为对端VTEP设备即flannel.1的MAC，IP为VTEP对应的对外IP（可通过flanneld的启动参数–iface=eth1指定，若不指定则按默认网关查找网络接口对应的IP），可以看到已经有两条转发表。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# bridge fdb show dev flannel.1</span><br><span class="line">42:7f:69:c7:cd:37 dst 172.16.130.164 self permanent</span><br><span class="line">7a:2c:d0:7f:48:3f dst 172.16.130.140 self permanent</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>从UDP更改到VXLAN的过程不多赘述，修改后同样可以通过netstat -ulnp命令查看VXLAN监听的端口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# netstat -ulnp | grep 8472</span><br><span class="line">udp        0      0 0.0.0.0:8472            0.0.0.0:*                           -</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>但跟UDP模式下查看flanneld监听的端口的区别为，最后一栏显示的不是进程的ID和名称，而是一个破折号“-”，这说明UDP的8472端口不是由用户态的进程在监听的，也证实了VXLAN模块工作在内核态模式下。<br><img src="https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/b8f4da7a3c4a65c48d227481279073b8.png"><br>此时容器跨节点网络通信实现流程为：</p>
<ul>
<li>同UDP Backend模式，容器A当中的IP包通过容器A内的路由表被发送到cni0</li>
<li>到达cni0当中的IP包通过匹配host A当中的路由表发现通往10.244.2.194的IP包应该交给flannel.1接口</li>
<li>flannel.1作为一个VTEP设备，收到报文后将按照VTEP的配置进行封包，首先通过etcd得知10.244.2.194属于节点B，并得到节点B的IP，通过节点A当中的转发表得到节点B对应的VTEP的MAC，根据flannel.1设备创建时的设置的参数（VNI、local IP、Port）进行VXLAN封包</li>
<li>通过host A跟host B之间的网络连接，VXLAN包到达host B的eth1接口</li>
<li>通过端口8472，VXLAN包被转发给VTEP设备flannel.1进行解包</li>
<li>解封装后的IP包匹配host B当中的路由表（10.244.2.0），内核将IP包转发给cni0</li>
<li>cni0将IP包转发给连接在cni0上的容器B</li>
</ul>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.sdnlab.com/24272.html">Kubernetes网络模型</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/06/kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/" data-id="ckh65smu20000xovxd8pe70l2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes-network/" rel="tag">kubernetes network</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-linux虚拟网络模型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/06/linux%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time datetime="2020-11-06T02:56:49.000Z" itemprop="datePublished">2020-11-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/06/linux%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">linux虚拟网络模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Linux-虚拟网络模型"><a href="#Linux-虚拟网络模型" class="headerlink" title="Linux 虚拟网络模型"></a>Linux 虚拟网络模型</h1><p>为了支持网络协议栈的多个实例，linux在网络协议栈引入了网络命名空间，这些独立的协议栈被隔离到不同 的命名空间中，处于不同的命名空间的网络协议栈事完全隔离的，彼此之间无法通信。docker 就是通过这种实现了不同容器之间的隔离。Veth这个设备对可以联通两个不同的命名空间，使得两个命名空间可以通信，在多个命名空间时则多会使用bridge，Netfilter和iptables则实现了数据包的过滤、修改和丢弃，本文将会从这几点讲述如何实现linux虚拟网络模型。</p>
<h2 id="从netns和veth说起"><a href="#从netns和veth说起" class="headerlink" title="从netns和veth说起"></a>从netns和veth说起</h2><p>netns是linux的网络命名空间，它们之间的网络是隔离的，veth则可以联通两个不同的命名空间。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1  ip netns add ns1</span><br><span class="line">2  ip netns ls</span><br><span class="line">3  ip netns add ns2</span><br><span class="line"><span class="meta">#</span><span class="bash">创建了两个命名空间</span></span><br><span class="line">4  ip link add veth0 type veth peer name veth1</span><br><span class="line"><span class="meta">#</span><span class="bash">创建了一对veth，veth总是成对出现的</span></span><br><span class="line">5  ip link show</span><br></pre></td></tr></table></figure>
<p>到这里命名空间和veth都创建完毕，可以通过<code>ip netns ls</code>和<code>ip link show</code>分别看到。<br><code>ip netns ls</code>的结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ns2</span><br><span class="line">ns1 (id: 0)</span><br></pre></td></tr></table></figure>
<p><code>ip link show</code>的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 9001 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000</span><br><span class="line">    link&#x2F;ether 06:99:32:53:81:1e brd ff:ff:ff:ff:ff:ff</span><br><span class="line">3: veth1@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link&#x2F;ether 7e:8d:5f:08:37:21 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">4: veth0@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link&#x2F;ether 4e:22:2b:5e:8e:1f brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure>
<p>接下来我们把veth绑在netns上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6  ip link set veth1 netns ns1</span><br><span class="line">8  ip link set veth0 netns ns2</span><br></pre></td></tr></table></figure>
<p>再执行<code>ip link show</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 9001 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000</span><br><span class="line">    link&#x2F;ether 06:99:32:53:81:1e brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure>
<p>可以看到已经看不到之前的veth，他们已经被绑在了ns1和ns2上了，此时可以通过<code>ip netns exec ns1 ip link show</code>来看<br>执行<code>ip netns exec ns1 ip link show</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">3: veth1@if4: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link/ether 7e:8d:5f:08:37:21 brd ff:ff:ff:ff:ff:ff link-netnsid 1</span><br></pre></td></tr></table></figure>
<p>同时，已被绑定的veth也可以通过<code>ip netns exec ns1</code>执行<code>ip link</code>命令进行换绑</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">11  ip netns exec ns1 ip link set veth1 netns ns2</span><br><span class="line">13  ip netns exec ns2 ip link set veth0 netns ns1</span><br></pre></td></tr></table></figure>
<p>此时他们的veth交换了位置，现在两个veth绑定到了两个netns里，但是他们还不可以通信，因为没有绑定ip，现在我们来绑定ip</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">14  ip netns exec ns1 ip addr add 10.1.1.1/24 dev veth0</span><br><span class="line">15  ip netns exec ns2 ip addr add 10.1.1.2/24 dev veth1</span><br></pre></td></tr></table></figure>
<p>启动两个ip</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">16  ip netns exec ns1 ip link set dev veth0 up</span><br><span class="line">17  ip netns exec ns2 ip link set dev veth1 up</span><br></pre></td></tr></table></figure>
<p>尝试ping一下<code>ip netns exec ns1 ping 10.1.1.2</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.1.1.2: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.035 ms</span><br><span class="line">64 bytes from 10.1.1.2: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.028 ms</span><br><span class="line">64 bytes from 10.1.1.2: icmp_seq&#x3D;3 ttl&#x3D;64 time&#x3D;0.028 ms</span><br><span class="line">64 bytes from 10.1.1.2: icmp_seq&#x3D;4 ttl&#x3D;64 time&#x3D;0.030 ms</span><br><span class="line">^C</span><br><span class="line">--- 10.1.1.2 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 2997ms</span><br><span class="line">rtt min&#x2F;avg&#x2F;max&#x2F;mdev &#x3D; 0.028&#x2F;0.030&#x2F;0.035&#x2F;0.004 ms</span><br></pre></td></tr></table></figure>
<p>Ohhhhhhhhhh，成功了。</p>
<h2 id="Bridge使通讯更丰富"><a href="#Bridge使通讯更丰富" class="headerlink" title="Bridge使通讯更丰富"></a>Bridge使通讯更丰富</h2><p>Linux内核是通过一个虚拟的网桥设备来实现桥接的，这个虚拟设备可以绑定若干个接口设备，从将他们桥接起来，作为关键的是，它还可以有一个ip地址。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip netns delete ns1</span><br><span class="line">ip netns delete ns2</span><br></pre></td></tr></table></figure>
<p>先把之前的两个网络空间删掉，然后开始下面的配置<br>先配置ns1</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建 Network Namespace 1</span></span><br><span class="line">sudo ip netns add ns1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 veth</span></span><br><span class="line">sudo ip link add veth0 type veth peer name veth_ns_1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将一个veth移至 ns1 中</span></span><br><span class="line">sudo ip link set veth0 netns ns1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置这个veth的ip，并启用 ns1 中的网络接口</span></span><br><span class="line">sudo ip netns exec ns1 ifconfig veth0 175.18.0.2/24 up</span><br><span class="line">sudo ip netns exec ns1 ifconfig lo up</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启用留在默认网络命名空间中的虚拟网卡</span></span><br><span class="line">sudo ifconfig veth_ns_1 up</span><br></pre></td></tr></table></figure>
<p>查看ns1中的网络情况<code>ip netns exec ns1 ip addr</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: veth0@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link&#x2F;ether a6:04:d5:bb:ec:30 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 175.18.0.2&#x2F;24 brd 175.18.0.255 scope global veth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::a404:d5ff:febb:ec30&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>
<p>对于ns2采取同样的操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo ip netns add ns2</span><br><span class="line">sudo ip link add veth0 type veth peer name veth_ns_2</span><br><span class="line">sudo ip link set veth0 netns ns2</span><br><span class="line">sudo ip netns exec ns2 ifconfig veth0 175.18.0.3/24 up</span><br><span class="line">sudo ip netns exec ns2 ifconfig lo up</span><br><span class="line">sudo ifconfig veth_ns_2 up</span><br></pre></td></tr></table></figure>
<p>接下来配置网桥，主要是把两个留出来的veth端绑在bridge上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一个网桥</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> brctl在 bridge-utils 软件包中，没有的话需要使用 apt-get 下载</span></span><br><span class="line">sudo brctl addbr ns_br</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置网桥的ip，并启用</span></span><br><span class="line">sudo ifconfig ns_br 175.18.0.1/24 up</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置路由</span></span><br><span class="line">sudo route add -net 175.18.0.0/24 dev ns_br</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将两个虚拟网卡添加到网桥上</span></span><br><span class="line">sudo brctl addif ns_br veth_ns_1</span><br><span class="line">sudo brctl addif ns_br veth_ns_2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置两个网络命名空间的默认路由</span></span><br><span class="line">sudo ip netns exec ns1 ip route add default via 175.18.0.1 dev veth0</span><br><span class="line">sudo ip netns exec ns2 ip route add default via 175.18.0.1 dev veth0</span><br></pre></td></tr></table></figure>
<p>现在bridge和两个netns都可通信了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo ip netns exec ns2 ping 175.18.0.1</span><br><span class="line">sudo ip netns exec ns1 ping 175.18.0.1</span><br><span class="line">sudo ping -I ns_br 175.18.0.2</span><br><span class="line">sudo ping -I ns_br 175.18.0.3</span><br></pre></td></tr></table></figure>
<p>但是，它们之间是无法通信的，或许也有可能，这个就牵涉到 iptables 的问题了。</p>
<h2 id="Linux-iptables"><a href="#Linux-iptables" class="headerlink" title="Linux iptables"></a>Linux iptables</h2><p>如果说bridge的作用像一个交换机，那iptable则是负责过滤交换机上转发的数据包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure>
<p>首先看一下转发功能有没有开启，如果返回为零</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv4.conf.all.forwarding=1</span><br></pre></td></tr></table></figure>
<p>开启转发，再去看的时候就会返回1了<br>iptables 有五个表（table），这里先查看 FILTER 表，输入如下命令查看</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t filter -n --list</span><br></pre></td></tr></table></figure>
<p>关注Forward，它用于处理转发规则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Chain FORWARD (policy ACCEPT)</span><br></pre></td></tr></table></figure>
<p>如果你的policy 是DROP的话可以执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t filter --policy FORWARD ACCEPT</span><br></pre></td></tr></table></figure>
<p>这样就可以对数据包放行，再去ping的时候就可以ping通了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip netns exec ns1 ping -c 3 175.18.0.3</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PING 175.18.0.3 (175.18.0.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 175.18.0.3: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.038 ms</span><br><span class="line">64 bytes from 175.18.0.3: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.041 ms</span><br><span class="line">64 bytes from 175.18.0.3: icmp_seq&#x3D;3 ttl&#x3D;64 time&#x3D;0.041 ms</span><br><span class="line"></span><br><span class="line">--- 175.18.0.3 ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 1999ms</span><br><span class="line">rtt min&#x2F;avg&#x2F;max&#x2F;mdev &#x3D; 0.038&#x2F;0.040&#x2F;0.041&#x2F;0.001 ms</span><br></pre></td></tr></table></figure>
<p>ping本机的ip也没有问题</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip netns exec ns1 ping 172.31.30.66</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PING 172.31.30.66 (172.31.30.66) 56(84) bytes of data.</span><br><span class="line">64 bytes from 172.31.30.66: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.029 ms</span><br><span class="line">64 bytes from 172.31.30.66: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.036 ms</span><br><span class="line">64 bytes from 172.31.30.66: icmp_seq&#x3D;3 ttl&#x3D;64 time&#x3D;0.036 ms</span><br><span class="line">^C</span><br><span class="line">--- 172.31.30.66 ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 1998ms</span><br><span class="line">rtt min&#x2F;avg&#x2F;max&#x2F;mdev &#x3D; 0.029&#x2F;0.033&#x2F;0.036&#x2F;0.007 ms</span><br></pre></td></tr></table></figure>
<p>但如果你尝试去ping 外部其他ip的时候就会发现无法ping通，以百度为例。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">root@ip-172-31-30-66:~# ping www.baidu.com</span><br><span class="line">PING www.a.shifen.com (220.181.38.149) 56(84) bytes of data.</span><br><span class="line">64 bytes from 220.181.38.149: icmp_seq&#x3D;1 ttl&#x3D;46 time&#x3D;21.6 ms</span><br><span class="line">64 bytes from 220.181.38.149: icmp_seq&#x3D;2 ttl&#x3D;46 time&#x3D;21.7 ms</span><br><span class="line">^C</span><br><span class="line">--- www.a.shifen.com ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 1001ms</span><br><span class="line">rtt min&#x2F;avg&#x2F;max&#x2F;mdev &#x3D; 21.625&#x2F;21.670&#x2F;21.716&#x2F;0.154 ms</span><br><span class="line"></span><br><span class="line">root@ip-172-31-30-66:~# ip netns exec ns1 ping 220.181.38.149</span><br><span class="line">#不ping域名的原因是无法对其解析</span><br><span class="line"></span><br><span class="line">PING 220.181.38.149 (220.181.38.149) 56(84) bytes of data.</span><br><span class="line">^C</span><br><span class="line">--- 220.181.38.149 ping statistics ---</span><br><span class="line">4 packets transmitted, 0 received, 100% packet loss, time 2999ms</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这是因为从 ns1 发送 ICMP 报文至 220.181.38.149 是可以成功的，此时报文的源地址为 175.18.0.2 。但是在 220.181.38.149 回复报文的时候，ICMP 报文的目的地址为 175.18.0.2，这个是一个内网的IP，所以数据包必然丢失。</p>
<p>所以需要在数据包离开之前将源地址修改为172.31.30.66对应的外网ip，iptables的NET表就是用来做这个的</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -A POSTROUTING -s 175.18.0.0/24 -j MASQUERADE</span><br></pre></td></tr></table></figure>
<p>POSTROUTING 链也为 iptables 的五个链之一，是用来做 SNAT （源地址转换的），而 MASQUERADE 策略是：报文从哪个网卡出就用该网卡上的 IP 地址替换该报文的源地址，而在这里， 175.18.0.2 被 172.31.30.66的外网地址替换。 -A 表示 append，也就是向 NAT 表的 POSTROUTING 链追加设置，如果把 -A 换成 -D 则为删除此规则。-t 用于指定表（table）， -s 表示源地址， -j 表示 jump。<br>再去ping一下baidu</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip netns exec ns1 ping -c 3 www.baidu.com</span><br><span class="line"><span class="meta">#</span><span class="bash">现在也可以从DNS解析IP了</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PING www.a.shifen.com (220.181.38.150) 56(84) bytes of data.</span><br><span class="line">64 bytes from 220.181.38.150: icmp_seq&#x3D;1 ttl&#x3D;45 time&#x3D;20.6 ms</span><br><span class="line">64 bytes from 220.181.38.150: icmp_seq&#x3D;2 ttl&#x3D;45 time&#x3D;20.7 ms</span><br><span class="line">64 bytes from 220.181.38.150: icmp_seq&#x3D;3 ttl&#x3D;45 time&#x3D;20.7 ms</span><br><span class="line"></span><br><span class="line">--- www.a.shifen.com ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 2003ms</span><br><span class="line">rtt min&#x2F;avg&#x2F;max&#x2F;mdev &#x3D; 20.630&#x2F;20.706&#x2F;20.751&#x2F;0.174 ms</span><br></pre></td></tr></table></figure>
<p>到现在两个网络空间已经都可以请求外部了，那他们如何被外部访问呢？<br>先在两个网络空间内启动python的web服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip netns exec ns1 nohup python3 -m http.server 80 &amp;</span><br><span class="line">ip netns exec ns2 nohup python3 -m http.server 80 &amp; </span><br></pre></td></tr></table></figure>
<p>可以直接curl到两个服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@ip-172-31-30-66:~# curl -I http:&#x2F;&#x2F;175.18.0.2</span><br><span class="line">HTTP&#x2F;1.0 200 OK</span><br><span class="line">Server: SimpleHTTP&#x2F;0.6 Python&#x2F;3.5.2</span><br><span class="line">Date: Fri, 06 Nov 2020 06:30:38 GMT</span><br><span class="line">Content-type: text&#x2F;html; charset&#x3D;utf-8</span><br><span class="line">Content-Length: 629</span><br><span class="line"></span><br><span class="line">root@ip-172-31-30-66:~# curl -I http:&#x2F;&#x2F;175.18.0.3</span><br><span class="line">HTTP&#x2F;1.0 200 OK</span><br><span class="line">Server: SimpleHTTP&#x2F;0.6 Python&#x2F;3.5.2</span><br><span class="line">Date: Fri, 06 Nov 2020 06:30:38 GMT</span><br><span class="line">Content-type: text&#x2F;html; charset&#x3D;utf-8</span><br><span class="line">Content-Length: 629</span><br></pre></td></tr></table></figure>
<p>docker -p/-P的映射是将容器中的端口和物理机端口做了映射，这个映射使用 iptables 实现的，我们也可以用iptables来实现映射。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 8088 -j DNAT --to 175.18.0.2:80</span><br><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 8089 -j DNAT --to 175.18.0.3:80</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>现在两个pthon3打开的文件服务器已经开放在8088和8089啦</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>本文中讲解的linux虚拟网络模型十分的基础，和docker所实现的网络模型相差很大，但原理有所相通，后续会继续搞docker、kubernetes、istio的网络模型分析实验，欢迎关注👏</p>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ul>
<li>[1] <a target="_blank" rel="noopener" href="https://blog.schwarzeni.com/2019/12/28/veth-iptables-%E6%A8%A1%E6%8B%9F-Docker-%E7%BD%91%E7%BB%9C-Bridge-%E6%A8%A1%E5%BC%8F/">veth + iptables 模拟 Docker 网络 Bridge 模式</a></li>
<li>[2] <a href="">kubernetes权威指南</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/06/linux%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/" data-id="ckh5q7rva0000jmvxann8ewzz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux-bridge-veth-netns-iptables-netfilter/" rel="tag">linux bridge veth netns iptables netfilter</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-数据中台概念篇——数据服务中心" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E5%BF%83/" class="article-date">
  <time datetime="2020-11-02T07:50:39.000Z" itemprop="datePublished">2020-11-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E5%BF%83/">数据中台概念篇——数据服务中心</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>开坑</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E5%BF%83/" data-id="ckh0a8y0b0005uwvxa1ge2bc6" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据中台概念篇——数据质量中心" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E4%B8%AD%E5%BF%83/" class="article-date">
  <time datetime="2020-11-02T07:50:32.000Z" itemprop="datePublished">2020-11-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E4%B8%AD%E5%BF%83/">数据中台概念篇——数据质量中心</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>开坑</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E4%B8%AD%E5%BF%83/" data-id="ckh0a8y0e0008uwvx88hx67sv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据中台概念篇——存储优化中心" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E5%AD%98%E5%82%A8%E4%BC%98%E5%8C%96%E4%B8%AD%E5%BF%83/" class="article-date">
  <time datetime="2020-11-02T07:49:35.000Z" itemprop="datePublished">2020-11-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E5%AD%98%E5%82%A8%E4%BC%98%E5%8C%96%E4%B8%AD%E5%BF%83/">数据中台概念篇——存储优化中心</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="数据存储优化中心搭建方案"><a href="#数据存储优化中心搭建方案" class="headerlink" title="数据存储优化中心搭建方案"></a>数据存储优化中心搭建方案</h1><p>数据存储一直是大数据系统的重中之重，根据预期数据的不同会有多种的选择方式，常见的问题会有：</p>
<ul>
<li>没有统一的规范标准管理，造成了重复计算的资源浪费</li>
<li>数据的层次和粒度不清晰，使得重复存储严重</li>
<li>性能不够，无法快速相应多维度查询</li>
<li>成本过高，方案无法执行下去  </li>
</ul>
<p>这些问题究其根本还是存储的成本和性能平衡，开发和运维平衡，我会大概阐述一下我的设计方案。</p>
<h2 id="一、数据存储预分层设计"><a href="#一、数据存储预分层设计" class="headerlink" title="一、数据存储预分层设计"></a>一、数据存储预分层设计</h2><p><img src="/images/database.jpg" alt="分层图" title="存储预分层"><br>数据依此分为ODS,DWD,DWS,ADM四层。</p>
<h5 id="ODS层"><a href="#ODS层" class="headerlink" title="ODS层"></a>ODS层</h5><p>从分布式消息队列中消费Binlog和Click-log，并对埋点数据进行清洗和业务库数据还原，并根据需要增量或全量同步到Hive，同时积累历史数据并保存。</p>
<h5 id="DWD层"><a href="#DWD层" class="headerlink" title="DWD层"></a>DWD层</h5><p>对整体业务进行概念抽象及适当冗余，在保证数据一致的同时将同属性实体归纳整合到同一逻辑域，减少存储空间，响应业务系统的变化，避免更新异常。</p>
<h5 id="DWS层"><a href="#DWS层" class="headerlink" title="DWS层"></a>DWS层</h5><p>采用维度建模方法，根据活动特点及事实场景，对代金券、现金券、促销等的事件进一步整合。经过对维度的预处理，在使用信息的时候，不但减少时间成本、提高数据的提取效率，又为用户在Ad-Hoc平台查询提供很好的支撑。</p>
<h5 id="ADM层"><a href="#ADM层" class="headerlink" title="ADM层"></a>ADM层</h5><p>ADM层则是服务于应用业务级别，它的数据来源可以是DWS或DWD，对于订单这种公司各部门普遍参与的类型数据从DWS层提取聚合，对于部门个性化应用则可从DWD层提取。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E5%AD%98%E5%82%A8%E4%BC%98%E5%8C%96%E4%B8%AD%E5%BF%83/" data-id="ckh0a8y050001uwvx3ga44pil" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AD%98%E5%82%A8-%E6%88%90%E6%9C%AC-%E8%AE%A1%E7%AE%97-%E5%88%86%E5%B1%82/" rel="tag">存储 成本 计算 分层</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-数据中台概念篇——数据指标中心" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%8C%87%E6%A0%87%E4%B8%AD%E5%BF%83/" class="article-date">
  <time datetime="2020-11-02T07:49:28.000Z" itemprop="datePublished">2020-11-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%8C%87%E6%A0%87%E4%B8%AD%E5%BF%83/">数据中台概念篇——数据指标中心</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>开坑</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%8C%87%E6%A0%87%E4%B8%AD%E5%BF%83/" data-id="ckh0a8y0a0004uwvxebmv6pbr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据中台概念篇——异构数据采集" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E5%BC%82%E6%9E%84%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" class="article-date">
  <time datetime="2020-11-02T07:48:57.000Z" itemprop="datePublished">2020-11-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E5%BC%82%E6%9E%84%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/">数据中台概念篇——异构数据采集</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>开坑</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E5%BC%82%E6%9E%84%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" data-id="ckh0a8y090003uwvxbb9r69gt" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-kerberos" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/30/kerberos/" class="article-date">
  <time datetime="2020-10-30T07:34:14.000Z" itemprop="datePublished">2020-10-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/30/kerberos/">docker安装kerberos方案</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="kerberos安装与应用方案"><a href="#kerberos安装与应用方案" class="headerlink" title="kerberos安装与应用方案"></a>kerberos安装与应用方案</h1><h2 id="docker安装KDC"><a href="#docker安装KDC" class="headerlink" title="docker安装KDC"></a>docker安装KDC</h2><h3 id="打包docker镜像"><a href="#打包docker镜像" class="headerlink" title="打包docker镜像"></a>打包docker镜像</h3><p>Dockerfile：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:7</span><br><span class="line"></span><br><span class="line">RUN yum install -y krb5-server krb5-libs krb5-auth-dialog krb5-workstation</span><br><span class="line"></span><br><span class="line">CMD [<span class="string">&quot;/usr/sbin/init&quot;</span>]</span><br></pre></td></tr></table></figure>
<p>docker build：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t kdc:1.0 .</span><br></pre></td></tr></table></figure>
<h3 id="docker-启动"><a href="#docker-启动" class="headerlink" title="docker 启动"></a>docker 启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --privileged=<span class="literal">true</span> -p 88:88 -p 749:749 -p 750:750 -d  --name=<span class="string">&quot;my_kdc&quot;</span> kdc:1.0 </span><br></pre></td></tr></table></figure>
<h3 id="KDC-配置"><a href="#KDC-配置" class="headerlink" title="KDC 配置"></a>KDC 配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /var/kerberos/krb5kdc/kdc.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[kdcdefaults]</span></span><br><span class="line"><span class="string"> kdc_ports = 88</span></span><br><span class="line"><span class="string"> kdc_tcp_ports = 88</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string"> HADOOP.COM = &#123;</span></span><br><span class="line"><span class="string">  #master_key_type = aes256-cts</span></span><br><span class="line"><span class="string">  acl_file = /var/kerberos/krb5kdc/kadm5.acl</span></span><br><span class="line"><span class="string">  dict_file = /usr/share/dict/words</span></span><br><span class="line"><span class="string">  admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab</span></span><br><span class="line"><span class="string">  max_renewable_life = 7d</span></span><br><span class="line"><span class="string">  supported_enctypes = aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal</span></span><br><span class="line"><span class="string"> &#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/krb5.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">includedir /etc/krb5.conf.d/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[logging]</span></span><br><span class="line"><span class="string"> default = FILE:/var/log/krb5libs.log</span></span><br><span class="line"><span class="string"> kdc = FILE:/var/log/krb5kdc.log</span></span><br><span class="line"><span class="string"> admin_server = FILE:/var/log/kadmind.log</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[libdefaults]</span></span><br><span class="line"><span class="string"> dns_lookup_kdc = false</span></span><br><span class="line"><span class="string"> dns_lookup_realm = false</span></span><br><span class="line"><span class="string"> ticket_lifetime = 24h</span></span><br><span class="line"><span class="string"> renew_lifetime = 7d</span></span><br><span class="line"><span class="string"> forwardable = true</span></span><br><span class="line"><span class="string"> default_realm = HADOOP.COM</span></span><br><span class="line"><span class="string"> udp_preference_limit = 1</span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string"> HADOOP.COM = &#123;</span></span><br><span class="line"><span class="string">  kdc = kdc</span></span><br><span class="line"><span class="string">  admin_server = kdc</span></span><br><span class="line"><span class="string"> &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[domain_realm]</span></span><br><span class="line"><span class="string"> .hadoop.com = HADOOP.COM</span></span><br><span class="line"><span class="string"> hadoop.com = HADOOP.COM</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">cat  &gt;&gt;  /etc/hosts &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">127.0.0.1 kdc </span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">cat &gt; /var/kerberos/krb5kdc/kadm5.acl &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">*/admin@HADOOP.COM	*</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h3 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kdb5_util create -s -r HADOOP.COM</span><br></pre></td></tr></table></figure>
<p>输入密码</p>
<h3 id="启动KDC"><a href="#启动KDC" class="headerlink" title="启动KDC"></a>启动KDC</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start kadmin krb5kdc</span><br><span class="line">systemctl status kadmin krb5kdc</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/10/30/kerberos/" data-id="ckh0a8xzy0000uwvxgxphgxfe" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kerberos-%E5%AE%89%E5%85%A8-%E6%9D%83%E9%99%90/" rel="tag">kerberos 安全 权限</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/30/hello-world/" class="article-date">
  <time datetime="2020-10-30T03:07:21.804Z" itemprop="datePublished">2020-10-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/30/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/10/30/hello-world/" data-id="ckgvoya1m000063vx327iamzb" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/kerberos-%E5%AE%89%E5%85%A8-%E6%9D%83%E9%99%90/" rel="tag">kerberos 安全 权限</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kubernetes-network/" rel="tag">kubernetes network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux-bridge-veth-netns-iptables-netfilter/" rel="tag">linux bridge veth netns iptables netfilter</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%98%E5%82%A8-%E6%88%90%E6%9C%AC-%E8%AE%A1%E7%AE%97-%E5%88%86%E5%B1%82/" rel="tag">存储 成本 计算 分层</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/kerberos-%E5%AE%89%E5%85%A8-%E6%9D%83%E9%99%90/" style="font-size: 10px;">kerberos 安全 权限</a> <a href="/tags/kubernetes-network/" style="font-size: 10px;">kubernetes network</a> <a href="/tags/linux-bridge-veth-netns-iptables-netfilter/" style="font-size: 10px;">linux bridge veth netns iptables netfilter</a> <a href="/tags/%E5%AD%98%E5%82%A8-%E6%88%90%E6%9C%AC-%E8%AE%A1%E7%AE%97-%E5%88%86%E5%B1%82/" style="font-size: 10px;">存储 成本 计算 分层</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/11/06/kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">kubernetes网络模型</a>
          </li>
        
          <li>
            <a href="/2020/11/06/linux%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">linux虚拟网络模型</a>
          </li>
        
          <li>
            <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E5%BF%83/">数据中台概念篇——数据服务中心</a>
          </li>
        
          <li>
            <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E4%B8%AD%E5%BF%83/">数据中台概念篇——数据质量中心</a>
          </li>
        
          <li>
            <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E5%AD%98%E5%82%A8%E4%BC%98%E5%8C%96%E4%B8%AD%E5%BF%83/">数据中台概念篇——存储优化中心</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Ryan<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>