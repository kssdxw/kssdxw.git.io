<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>kubernetes网络模型 | Ryan&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="背景计算、存储和网络是云时代的三大基础服务，作为新一代基础架构的 Kubernetes 也不例外。而这三者之中，网络又是一个最难掌握和最容易出问题的服务；本文通过对Kubernetes网络流量模型进行简单梳理，希望对初学者能够提供一定思路。先看一下kubernetes 总体模型：  容器网络中涉及的几个地址：Node Ip：物理机地址。POD Ip：Kubernetes的最小部署单元是Pod，一个">
<meta property="og:type" content="article">
<meta property="og:title" content="kubernetes网络模型">
<meta property="og:url" content="http://example.com/2020/11/06/kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="Ryan&#39;s Blog">
<meta property="og:description" content="背景计算、存储和网络是云时代的三大基础服务，作为新一代基础架构的 Kubernetes 也不例外。而这三者之中，网络又是一个最难掌握和最容易出问题的服务；本文通过对Kubernetes网络流量模型进行简单梳理，希望对初学者能够提供一定思路。先看一下kubernetes 总体模型：  容器网络中涉及的几个地址：Node Ip：物理机地址。POD Ip：Kubernetes的最小部署单元是Pod，一个">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k1.png">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k2.jpg">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k3.PNG">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k4.png">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k5.png">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k6.PNG">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k7.PNG">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k8.png">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k9.PNG">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k10.png">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k11.PNG">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k12.PNG">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k13.PNG">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k14.PNG">
<meta property="og:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k15.PNG">
<meta property="og:image" content="https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/b8f4da7a3c4a65c48d227481279073b8.png">
<meta property="og:image" content="https://static001.infoq.cn/resource/image/43/df/43e371ee592ce23150091959343aa4df.png">
<meta property="og:image" content="https://static001.infoq.cn/resource/image/c8/f8/c8b8936834d450d273c2b4d11f1f1ef8.png">
<meta property="og:image" content="https://static001.infoq.cn/resource/image/99/52/99412b1688581f0444f334e7796b0052.png">
<meta property="og:image" content="https://static001.infoq.cn/resource/image/07/d1/073754a577bae1489a633c004538d6d1.png">
<meta property="og:image" content="https://static001.infoq.cn/resource/image/93/ba/936636bee23136bf16a6d1cdb47d98ba.png">
<meta property="article:published_time" content="2020-11-06T09:33:32.000Z">
<meta property="article:modified_time" content="2020-11-09T07:22:23.450Z">
<meta property="article:author" content="Ryan">
<meta property="article:tag" content="kubernetes network">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k1.png">
  
    <link rel="alternate" href="/atom.xml" title="Ryan&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Ryan&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-kubernetes网络模型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/06/kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time datetime="2020-11-06T09:33:32.000Z" itemprop="datePublished">2020-11-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      kubernetes网络模型
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>计算、存储和网络是云时代的三大基础服务，作为新一代基础架构的 Kubernetes 也不例外。而这三者之中，网络又是一个最难掌握和最容易出问题的服务；本文通过对Kubernetes网络流量模型进行简单梳理，希望对初学者能够提供一定思路。先看一下kubernetes 总体模型：</p>
<p><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k1.png"></p>
<h4 id="容器网络中涉及的几个地址："><a href="#容器网络中涉及的几个地址：" class="headerlink" title="容器网络中涉及的几个地址："></a>容器网络中涉及的几个地址：</h4><p>Node Ip：物理机地址。<br>POD Ip：Kubernetes的最小部署单元是Pod，一个pod 可能包含一个或多个容器，简单来讲容器没有自己单独的地址，他们共享POD 的地址和端口区间。<br>ClusterIp：Service的Ip地址，外部网络无法ping通改地址，因为它是虚拟IP地址，没有网络设备为这个地址负责，内部实现是使用Iptables规则重新定向到其本地端口，再均衡到后端Pod；只有Kubernetes集群内部访问使用。<br>Public Ip ：Service对象在Cluster IP range池中分配到的IP只能在内部访问，适合作为一个应用程序内部的层次。如果这个Service作为前端服务，准备为集群外的客户提供业务，我们就需要给这个服务提供公共IP。</p>
<h2 id="容器网络流量模型"><a href="#容器网络流量模型" class="headerlink" title="容器网络流量模型"></a>容器网络流量模型</h2><p>容器网络至少需要解决如下几种场景的通信：</p>
<p>①POD内容器间通信<br>②同主机POD间 通信<br>③跨主机POD间 通信<br>④集群内Service Cluster Ip和外部访问</p>
<p>下面具体介绍实现方式</p>
<h4 id="POD内容器间通信"><a href="#POD内容器间通信" class="headerlink" title="POD内容器间通信"></a>POD内容器间通信</h4><p>Pod中的容器可以通过“localhost”来互相通信，他们使用同一个网络命名空间，对容器来说，hostname就是Pod的名称。Pod中的所有容器共享同一个IP地址和端口空间，你需要为每个需要接收连接的容器分配不同的端口。也就是说，Pod中的应用需要自己协调端口的使用。</p>
<p>实验如下：</p>
<p>首先我们创建一个Pod ，包含两个容器，容器参数如下：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k2.jpg"><br>查看：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k3.PNG"><br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k4.png"><br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k5.png"></p>
<p>可以看到容器共享Pod 的地址，那么他们是否使用同一端口资源呢，我们可以简单实验一下：首先在容器1监听一个端口：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k6.PNG"><br>然后在容器2查看该端口是否被占用：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k7.PNG"><br>可见端口也是共享的；所以简单理解，可以把Pod看做一个小系统，容器当做系统中的不同进程；</p>
<p>内部实现：同POD 内的容器实际共享同一个Namespace，因此使用相同的Ip和Port空间，该Namespace 是由一个叫Pause的小容器来实现，每当一个Pod被创建，那么首先创建一个pause容器， 之后这个pod里面的其他容器通过共享这个pause容器的网络栈，实现外部pod进行通信,因此对于同Pod里面的所有容器来说，他们看到的网络视图是一样的，我们在容器中看的地址，也就是Pod地址实际是Pause容器的IP地址。总体模型如下：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k8.png"><br>我们在node 节点查看之前创建的POD，可以看到该pause容器 ：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k9.PNG"><br>这种新创建的容器和已经存在的一个容器(pause)共享一个 Network Namespace（而不是和宿主机共享） 就是我们常说的container 模式。</p>
<h4 id="同主机POD间通信"><a href="#同主机POD间通信" class="headerlink" title="同主机POD间通信"></a>同主机POD间通信</h4><p>每个节点上的每个Pod都有自己的namespace，同主机上的POD之间怎么通信呢？我们可以在两个POD之间建立Vet Pair进行通信，但如果有多个容器，两两建立Veth 就会非常麻烦，假如有N 个POD ，那么我们需要创建n(n-1)/2个Veth Pair，扩展性非常差，如果我们可以将这些Veth Pair 连接到一个集中的转发点，由它来统一转发就就会非常便捷，这个集中转发点就是我们常说的bridge；如下所示（简单起见，这里把pause忽略）：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k10.png"><br>仍然以我们的测试环境为例，创建pod1 和pod2地址分别为：10.244.1.16、10.244.1.18，位于node1 节点<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k11.PNG"><br>查看节点下的namespace：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k12.PNG"><br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k13.PNG"><br>这两个NS就是上述两个POD 对应的namespace，查询对应namespace 下的接口：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k14.PNG"><br>可以看到标红处的地址，实际就是POD 的ip地址；</p>
<p>NS 和对应的POD 地址都找到了，那么如何确认这两个ns 下的虚接口的另一端呢? 比较直观的确认方式为：上述接口如 3: eth0@if7，表示本端接口id 为3 ，对端接口id是7，我们看下default namespace（我们平时看的默认都在default下） 的veth口：<br><img src="https://img1.sdnlab.com//wp-content/uploads/2020/07/06/k15.PNG"><br>7: veth3b416eb5@if3 ，该接口的id 正是我们要找的id 为7的接口 ，是veth pair的另一端；</p>
<h2 id="跨node通信"><a href="#跨node通信" class="headerlink" title="跨node通信"></a>跨node通信</h2><p>跨node通信就涉及到了Container Network Interface的实现，也就是容器网络的API，它有一定的要求，简要下来有三点</p>
<ol>
<li>运行在一个节点当中的Pod能在不经过NAT的情况下跟集群中所有的Pod进行通信</li>
<li>节点当中的客户端（system daemon、kubelet）能跟该节点当中的所有Pod进行通信</li>
<li>以host network模式运行在一个节点上的Pod能跟集群中所有的Pod进行通信</li>
</ol>
<p>针对Kubernetes网络模型也涌现出了许多的实现方案，例如Calico、Flannel、Weave等等，虽然实现原理各有千秋，但都围绕着同一个问题即如何实现Kubernetes当中的扁平网络进行展开。Kubernetes只需要负责编排调度相关的事情，修桥铺路的事情交给相应的网络插件即可，我们会以Flannel为例进行讲解。</p>
<h4 id="Flannel"><a href="#Flannel" class="headerlink" title="Flannel"></a>Flannel</h4><p>不过多讲述部署过程，在安装部署完成之后应该能看到在各个节点上通过DaemonSet的方式运行了一个Flannel的Pod。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# kubectl get daemonset -n kube-system -l app&#x3D;flannel</span><br><span class="line">NAME              DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR                   AGE</span><br><span class="line">kube-flannel-ds   3         3         3         3            3           beta.kubernetes.io&#x2F;arch&#x3D;amd64   135d</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line">[root@10-10-88-192 ~]# kubectl get pod -n kube-system -o wide -l app&#x3D;flannel</span><br><span class="line">NAME                    READY     STATUS    RESTARTS   AGE       IP               NODE</span><br><span class="line">kube-flannel-ds-npcxv   1&#x2F;1       Running   0          2h        172.16.130.164   10-10-88-170</span><br><span class="line">kube-flannel-ds-rv8wv   1&#x2F;1       Running   0          2h        172.16.130.244   10-10-88-192</span><br><span class="line">kube-flannel-ds-t5zlv   1&#x2F;1       Running   0          2h        172.16.130.140   10-10-88-195</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>每一个Flannel的Pod当中都运行了一个flanneld进程，且flanneld的配置文件以ConfigMap的形式挂载到容器内的/etc/kube-flannel/目录供flanneld使用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# kubectl get cm -n kube-system -l app&#x3D;flannel</span><br><span class="line">NAME               DATA      AGE</span><br><span class="line">kube-flannel-cfg   2         137d</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>Flannel Backend<br>Flannel通过在每一个节点上启动一个叫flanneld的进程，负责每一个节点上的子网划分，并将相关的配置信息如各个节点的子网网段、外部IP等保存到etcd当中，而具体的网络包转发交给具体的Backend来实现。<br>flanneld可以在启动的时候通过配置文件来指定不同的Backend来进行网络通信，目前比较成熟的Backend有VXLAN、host-gw以及UDP三种方式，也已经有诸如AWS，GCE and AliVPC这些还在实验阶段的Backend。VXLAN是目前官方最推崇的一种Backend实现方式，host-gw一般用于对网络性能要求比较高的场景，但需要基础架构本身的支持，UDP则一般用于Debug和一些比较老的不支持VXLAN的Linux内核。<br>这里只简单介绍一下两种Backend网络通信实现流程：</p>
<ul>
<li>UDP</li>
<li>VXLAN<h4 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h4>由于UDP模式相对容易理解，故这里先采用UDP这种Backend模式进行举例说明然后再对其他Backend模式进行展开讲解。<br>采用UDP模式时需要在flanneld的配置文件当中指定Backend type为UDP，可以通过直接修改flanneld的ConfigMap的方式实现，配置修改完成之后如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# kubectl get cm -n kube-system -o yaml kube-flannel-cfg</span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  cni-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;cbr0&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;flannel&quot;,</span><br><span class="line">      &quot;delegate&quot;: &#123;</span><br><span class="line">        &quot;isDefaultGateway&quot;: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  net-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;Network&quot;: &quot;10.244.0.0/16&quot;,</span><br><span class="line">      &quot;Backend&quot;: &#123;</span><br><span class="line">        &quot;Type&quot;: &quot;udp&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: 2018-10-30T08:34:01Z</span><br><span class="line">  labels:</span><br><span class="line">    app: flannel</span><br><span class="line">    tier: node</span><br><span class="line">  name: kube-flannel-cfg</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  resourceVersion: &quot;33718154&quot;</span><br><span class="line">  selfLink: /api/v1/namespaces/kube-system/configmaps/kube-flannel-cfg</span><br><span class="line">  uid: 8d981eff-dc1e-11e8-8103-fa900126bc00</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
关键字段为Backend当中的Type字段，采用UDP模式时Backend Port默认为8285，即flanneld的监听端口。</li>
</ul>
<p>flanneld的ConfigMap更新完成之后delete flannel pod进行配置更新：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# kubectl delete pod -n kube-system -l app&#x3D;flannel</span><br><span class="line">pod &quot;kube-flannel-ds-npcxv&quot; deleted</span><br><span class="line">pod &quot;kube-flannel-ds-rv8wv&quot; deleted</span><br><span class="line">pod &quot;kube-flannel-ds-t5zlv&quot; deleted</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>当采用UDP模式时，flanneld进程在启动时会通过打开/dev/net/tun的方式生成一个TUN设备，TUN设备可以简单理解为Linux当中提供的一种内核网络与用户空间（应用程序）通信的一种机制，即应用可以通过直接读写tun设备的方式收发RAW IP包。</p>
<p>flanneld进程启动后通过ip a命令可以发现节点当中已经多了一个叫flannel0的网络接口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link&#x2F;ether fa:90:01:26:bc:00 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.10.88.192&#x2F;24 brd 10.10.88.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f890:1ff:fe26:bc00&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link&#x2F;ether fa:86:b8:79:70:01 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.16.130.244&#x2F;24 brd 172.16.130.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f886:b8ff:fe79:7001&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN</span><br><span class="line">    link&#x2F;ether 02:42:ae:dd:19:83 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1&#x2F;16 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: flannel0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1472 qdisc pfifo_fast state UNKNOWN qlen 500</span><br><span class="line">    link&#x2F;none</span><br><span class="line">    inet 10.244.0.0&#x2F;16 scope global flannel0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::969a:a8eb:e4da:308b&#x2F;64 scope link flags 800</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1472 qdisc noqueue state UP qlen 1000</span><br><span class="line">    link&#x2F;ether 0a:58:0a:f4:00:01 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.244.0.1&#x2F;24 scope global cni0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::3428:a4ff:fe6c:bb77&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>细心的同学就会发现此时flannel0这个网络接口上的MTU为1472，相比Kubernetes集群网络接口eth1小了28个字节，为什么呢？</p>
<p>通过可以ip -d link show flannel0可以看到这是一个tun设备：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# ip -d link show flannel0</span><br><span class="line">5: flannel0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1472 qdisc pfifo_fast state UNKNOWN mode DEFAULT qlen 500</span><br><span class="line">    link&#x2F;none  promiscuity 0</span><br><span class="line">    tun</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>通过netstat -ulnp命令可以看到此时flanneld进程监听在8285端口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# netstat -ulnp | grep flanneld</span><br><span class="line">udp        0      0 172.16.130.140:8285     0.0.0.0:*                           2373&#x2F;flanneld</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>容器跨节点通信实现流程：</p>
<p>假设在节点A上有容器A（10.244.1.96），在节点B上有容器B（10.244.2.194），此时容器A向容器发送一个ICMP请求报文（ping），我们来逐步分析一下ICMP报文是如何从容器A到达容器B的。<br><img src="https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/b8f4da7a3c4a65c48d227481279073b8.png"></p>
<p>1、容器A当中发出ICMP请求报文，通过IP封装后形式为：10.244.1.96 -&gt; 10.244.2.194，此时通过容器A内的路由表匹配到应该将IP包发送到网关10.244.1.1（cni0网桥）。</p>
<p>完整的帧格式为：</p>
<p><img src="https://static001.infoq.cn/resource/image/43/df/43e371ee592ce23150091959343aa4df.png"><br>2、此时到达cni0的IP包目的地IP 10.244.2.194匹配到节点A上第一条路由规则（10.244.0.0），内核将RAW IP包发送给flannel0接口。<br>3、flannel0为tun设备，发送给flannel0接口的RAW IP包（无MAC信息）将被flanneld进程接收到，flanneld进程接收到RAW IP包后在原有的基础上进行UDP封包，UDP封包的形式为：172.16.130.140:src port -&gt; 172.16.130.164:8285。<br>这里有一个问题就是flanneld怎么知道10.244.2.194这个容器到底是在哪个节点上呢？<br>flanneld在启动时会将该节点的网络信息通过api-server保存到etcd当中，故在发送报文时可以通过查询etcd得到10.244.2.194这个容器的IP属于host B，且host B的IP为172.16.130.164。<br>RAW IP包示例：<br><img src="https://static001.infoq.cn/resource/image/c8/f8/c8b8936834d450d273c2b4d11f1f1ef8.png"><br>4、flanneld将封装好的UDP报文经eth1发出，从这里可以看出网络包在通过eth1发出前先是加上了UDP头（8个字节），再然后加上了IP头（20个字节）进行封装，这也是为什么flannel0的MTU要比eth1的MTU小28个字节的原因（防止封装后的以太网帧超过eth1的MTU而在经过eth1时被丢弃）。<br>此时完整的以太网帧格式为：<br><img src="https://static001.infoq.cn/resource/image/99/52/99412b1688581f0444f334e7796b0052.png"><br>5、网络包经节点A和节点B之间的网络连接到达host B。<br>6、host B收到UDP报文后经Linux内核通过UDP端口号8285将包交给正在监听的应用flanneld。<br>7、运行在host B当中的flanneld将UDP包解包后得到RAW IP包：10.244.1.96 -&gt; 10.244.2.194。<br>8、解封后的RAW IP包匹配到host B上的路由规则（10.244.2.0），内核将RAW IP包发送到cni0。<br>此时的完整的以太网帧格式为：<br><img src="https://static001.infoq.cn/resource/image/07/d1/073754a577bae1489a633c004538d6d1.png"><br>9、cni0将IP包转发给连接在cni0网桥上的container B，而flanneld在整个过程中主要主要负责两个工作：</p>
<ul>
<li>UDP封包解包</li>
<li>节点上的路由表的动态更新<br>从上面虚线部分就可以看到container A和container B虽然在物理网络上并没有直接相连，但在逻辑上就好像是处于同一个三层网络当中，这种基于底下的物理网络设备通过Flannel等软件定义网络技术实现的网络我们称之为Overlay网络。<br>那么上面通过UDP这种Backend实现的网络传输过程有没有问题呢？最明显的问题就是，网络数据包先是通过tun设备从内核当中复制到用户态的应用，然后再由用户态的应用复制到内核，仅一次网络传输就进行了两次用户态和内核态的切换，显然这种效率是不会很高的。那么有没有高效一点的办法呢？当然，最简单的方式就是把封包解包这些事情都交给内核去干好了，事实上Linux内核本身也提供了比较成熟的网络封包解包（隧道传输）实现方案VXLAN，下面我们就来看看通过内核的VXLAN跟flanneld自己通过UDP封装网络包在实现上有什么差别。<h4 id="VXLAN"><a href="#VXLAN" class="headerlink" title="VXLAN"></a>VXLAN</h4>VXLAN全称Virtual Extensible LAN，是一种虚拟化隧道通信技术，主要是为了突破VLAN的最多4096个子网的数量限制，以满足大规模云计算数据中心的需求。VLAN技术的缺陷是VLAN Header预留的长度只有12 bit，故最多只能支持2的12次方即4096个子网的划分，无法满足云计算场景下主机数量日益增长的需求。当前VXLAN的报文Header内有24 bit，可以支持2的24次方个子网，并通过VNI（Virtual Network Identifier）来区分不同的子网，相当于VLAN当中的VLAN ID。<br>不同于其他隧道协议，VXLAN是一个一对多的网络，并不仅仅是一对一的隧道协议。一个VXLAN设备能通过像网桥一样的学习方式学习到其他对端的IP地址，也可以直接配置静态转发表。<br>VXLAN包格式：<br><img src="https://static001.infoq.cn/resource/image/93/ba/936636bee23136bf16a6d1cdb47d98ba.png"><br>从VXLAN的包格式就可以看到原本的二层以太网帧被放在VXLAN包头里进行封装，VXLAN实际实现的是一个二层网络的隧道，通过VXLAN让处于同一个VXLAN网络（VNI相同则为同一个VXLAN网络）当中的机器看似处在同一个二层网络当中（逻辑上处于同一个二层网络），而网络包转发的方式也类似二层网络当中的交换机（这样虽然不是很准确，但更便于理解）。<br>当采用VXLAN模式时，flanneld在启动时会通过Netlink机制与Linux内核通信，建立一个VTEP（Virtual Tunnel Access End Point）设备flannel.1 （命名规则为flannel.[VNI]，VNI默认为1），类似于交换机当中的一个网口。<br>可以通过ip -d link查看VTEP设备flannel.1的配置信息，从以下输出可以看到，VTEP的local IP为172.16.130.244，destination port为8472。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# ip -d link show flannel.1</span><br><span class="line">5: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT</span><br><span class="line">    link&#x2F;ether a2:5e:b0:43:09:a7 brd ff:ff:ff:ff:ff:ff promiscuity 0</span><br><span class="line">    vxlan id 1 local 172.16.130.244 dev eth1 srcport 0 0 dstport 8472 nolearning ageing 300 addrgenmode eui64</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>
在UDP模式下由flanneld进程进行网络包的封包和解包的工作，而在VXLAN模式下解封包的事情交由内核处理，那么此时FlannnelD的作用是什么呢？带着这个疑问我们先来简单看一下VXLAN Backend是如何工作的。</li>
</ul>
<p>Flannel当中对VXLAN Backend的实现经过了几个版本的改进之后目前最新版本的flanneld当中的处理流程为：</p>
<p>当flanneld启动时将创建VTEP设备（默认为flannel.1，若已经创建则跳过），并将VTEP设备的相关信息上报到etcd当中，而当在Flannel网络中有新的节点发现时，各个节点上的flanneld将依次执行以下流程：</p>
<p>在节点当中创建一条该节点所属网段的路由表，主要是能让Pod当中的流量路由到flannel.1接口。</p>
<p>通过route -n可以查看到节点当中已经有两条flannel.1接口的路由：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         10.10.88.254    0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">10.10.88.0      0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br><span class="line">10.244.0.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0</span><br><span class="line">10.244.1.0      10.244.1.0      255.255.255.0   UG    0      0        0 flannel.1</span><br><span class="line">10.244.2.0      10.244.2.0      255.255.255.0   UG    0      0        0 flannel.1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">172.16.130.0    0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">[root@10-10-88-192 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在节点当中添加一条该节点的IP以及VTEP设备的静态ARP缓存。<br>可通过arp -n命令查看到master节点当中已经缓存了另外两个节点以及VTEP的ARP信息（已删除无关ARP缓存信息）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# arp -n</span><br><span class="line">Address                  HWtype  HWaddress           Flags Mask            Iface</span><br><span class="line">10.244.2.0               ether   42:7f:69:c7:cd:37   CM                    flannel.1</span><br><span class="line">10.244.1.0               ether   7a:2c:d0:7f:48:3f   CM                    flannel.1</span><br><span class="line">172.16.130.140           ether   fa:89:cf:03:e3:01   C                     eth1</span><br><span class="line">172.16.130.164           ether   fa:88:2a:44:2b:01   C                     eth1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在节点当中添加一条该节点的转发表。<br>通过bridge命令查看节点上的VXLAN转发表（FDB entry），MAC为对端VTEP设备即flannel.1的MAC，IP为VTEP对应的对外IP（可通过flanneld的启动参数–iface=eth1指定，若不指定则按默认网关查找网络接口对应的IP），可以看到已经有两条转发表。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# bridge fdb show dev flannel.1</span><br><span class="line">42:7f:69:c7:cd:37 dst 172.16.130.164 self permanent</span><br><span class="line">7a:2c:d0:7f:48:3f dst 172.16.130.140 self permanent</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>从UDP更改到VXLAN的过程不多赘述，修改后同样可以通过netstat -ulnp命令查看VXLAN监听的端口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@10-10-88-192 ~]# netstat -ulnp | grep 8472</span><br><span class="line">udp        0      0 0.0.0.0:8472            0.0.0.0:*                           -</span><br><span class="line">[root@10-10-88-192 ~]#</span><br></pre></td></tr></table></figure>
<p>但跟UDP模式下查看flanneld监听的端口的区别为，最后一栏显示的不是进程的ID和名称，而是一个破折号“-”，这说明UDP的8472端口不是由用户态的进程在监听的，也证实了VXLAN模块工作在内核态模式下。</p>
<p>此时容器跨节点网络通信实现流程为：</p>
<ul>
<li>同UDP Backend模式，容器A当中的IP包通过容器A内的路由表被发送到cni0</li>
<li>到达cni0当中的IP包通过匹配host A当中的路由表发现通往10.244.2.194的IP包应该交给flannel.1接口</li>
<li>flannel.1作为一个VTEP设备，收到报文后将按照VTEP的配置进行封包，首先通过etcd得知10.244.2.194属于节点B，并得到节点B的IP，通过节点A当中的转发表得到节点B对应的VTEP的MAC，根据flannel.1设备创建时的设置的参数（VNI、local IP、Port）进行VXLAN封包</li>
<li>通过host A跟host B之间的网络连接，VXLAN包到达host B的eth1接口</li>
<li>通过端口8472，VXLAN包被转发给VTEP设备flannel.1进行解包</li>
<li>解封装后的IP包匹配host B当中的路由表（10.244.2.0），内核将IP包转发给cni0</li>
<li>cni0将IP包转发给连接在cni0上的容器B</li>
</ul>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul>
<li><a target="_blank" rel="noopener" href="https://www.sdnlab.com/24272.html">Kubernetes网络模型</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/06/kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/" data-id="ckh65smu20000xovxd8pe70l2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes-network/" rel="tag">kubernetes network</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2020/11/06/linux%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">linux虚拟网络模型</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/kerberos-%E5%AE%89%E5%85%A8-%E6%9D%83%E9%99%90/" rel="tag">kerberos 安全 权限</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kubernetes-network/" rel="tag">kubernetes network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux-bridge-veth-netns-iptables-netfilter/" rel="tag">linux bridge veth netns iptables netfilter</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%98%E5%82%A8-%E6%88%90%E6%9C%AC-%E8%AE%A1%E7%AE%97-%E5%88%86%E5%B1%82/" rel="tag">存储 成本 计算 分层</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/kerberos-%E5%AE%89%E5%85%A8-%E6%9D%83%E9%99%90/" style="font-size: 10px;">kerberos 安全 权限</a> <a href="/tags/kubernetes-network/" style="font-size: 10px;">kubernetes network</a> <a href="/tags/linux-bridge-veth-netns-iptables-netfilter/" style="font-size: 10px;">linux bridge veth netns iptables netfilter</a> <a href="/tags/%E5%AD%98%E5%82%A8-%E6%88%90%E6%9C%AC-%E8%AE%A1%E7%AE%97-%E5%88%86%E5%B1%82/" style="font-size: 10px;">存储 成本 计算 分层</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/11/06/kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">kubernetes网络模型</a>
          </li>
        
          <li>
            <a href="/2020/11/06/linux%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">linux虚拟网络模型</a>
          </li>
        
          <li>
            <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E5%BF%83/">数据中台概念篇——数据服务中心</a>
          </li>
        
          <li>
            <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E4%B8%AD%E5%BF%83/">数据中台概念篇——数据质量中心</a>
          </li>
        
          <li>
            <a href="/2020/11/02/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%A6%82%E5%BF%B5%E7%AF%87%E2%80%94%E2%80%94%E5%AD%98%E5%82%A8%E4%BC%98%E5%8C%96%E4%B8%AD%E5%BF%83/">数据中台概念篇——存储优化中心</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Ryan<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>